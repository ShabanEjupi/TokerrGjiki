================================================================
QUICK COMMAND REFERENCE - Server Deployment
================================================================

SERVER: 185.182.158.150:8022

------------------------------------------------------------
1. CONNECT TO SERVER (Manual)
------------------------------------------------------------
ssh -p 8022 username@185.182.158.150

OR use the script:
./connect_to_server.sh


------------------------------------------------------------
2. UPLOAD FILES TO SERVER
------------------------------------------------------------
# Upload Python script
scp -P 8022 retail_profiler.py username@185.182.158.150:~/pyspark_retail/

# Upload dataset
scp -P 8022 data_kaggle/online_retail.xlsx username@185.182.158.150:~/pyspark_retail/


------------------------------------------------------------
3. INSTALL DEPENDENCIES ON SERVER
------------------------------------------------------------
ssh -p 8022 username@185.182.158.150 << 'EOF'
pip install --user pyspark openpyxl pandas
EOF


------------------------------------------------------------
4. RUN ANALYSIS ON SERVER
------------------------------------------------------------
ssh -p 8022 username@185.182.158.150 << 'EOF'
cd ~/pyspark_retail
python retail_profiler.py
EOF


------------------------------------------------------------
5. DOWNLOAD RESULTS FROM SERVER
------------------------------------------------------------
# Download all outputs
scp -P 8022 -r username@185.182.158.150:~/pyspark_retail/out_retail ./results_from_server/

# Download specific file
scp -P 8022 username@185.182.158.150:~/pyspark_retail/out_retail/country_stats.csv .


------------------------------------------------------------
6. AUTOMATED DEPLOYMENT (All-in-one)
------------------------------------------------------------
./deploy_to_server.sh

(Note: Edit the script with your username first)


------------------------------------------------------------
7. CHECK SERVER STATUS
------------------------------------------------------------
ssh -p 8022 username@185.182.158.150 << 'EOF'
# Check if Python is installed
python --version

# Check if Java is installed (required for PySpark)
java -version

# Check disk space
df -h

# Check if files were uploaded
ls -lh ~/pyspark_retail/
EOF


------------------------------------------------------------
8. VIEW RESULTS ON SERVER
------------------------------------------------------------
ssh -p 8022 username@185.182.158.150 << 'EOF'
cd ~/pyspark_retail/out_retail
ls -lh
head -20 country_stats.csv
EOF


------------------------------------------------------------
TROUBLESHOOTING
------------------------------------------------------------

Connection refused?
→ Check if SSH is running: systemctl status sshd
→ Check firewall: sudo ufw status

Permission denied?
→ Ensure you have the correct username and password/key
→ Check: ssh-copy-id -p 8022 username@185.182.158.150

PySpark error?
→ Install Java: sudo apt-get install default-jdk
→ Check Python version: python --version (needs 3.8+)

Out of memory?
→ Reduce RETURNS_SAMPLE_LIMIT in retail_profiler.py
→ Check available RAM: free -h


================================================================
DATASET INFO
================================================================
Name: Online Retail Dataset (UCI)
Size: 541,909 transactions
Format: Excel (.xlsx, 22.6 MB)
Columns: 8 (InvoiceNo, StockCode, Description, Quantity, 
         InvoiceDate, UnitPrice, CustomerID, Country)

================================================================
OUTPUT FILES (9 files total in out_retail/)
================================================================
1. schema.json              - Data structure definition
2. null_counts.csv          - Missing value analysis
3. column_stats.csv         - Statistical summaries
4. country_stats.csv        - Revenue by country
5. product_stats.csv        - Top 1000 products
6. customer_stats.csv       - Top 5000 customers by spending
7. monthly_stats.csv        - Time-series metrics
8. metrics_sample.csv       - Sample with calculations
9. sample_20.csv            - First 20 rows

================================================================
