#!/usr/bin/env python3
"""
================================================================================
QUICK START - ML Pipeline Demo
================================================================================
Demonstrates the complete ML workflow with real algorithms
Run this to see everything in action!
================================================================================
"""

import os
import sys

# Add parent directory to path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(BASE_DIR)

def print_header(title):
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")

def main():
    print_header("üöÄ ML PIPELINE QUICK START")
    
    print("""
This demo will run the complete Machine Learning pipeline:

STEP 1: Feature Engineering (Spark)
  ‚úì Load raw price data
  ‚úì Calculate technical indicators (MA, RSI, Bollinger Bands, etc.)
  ‚úì Save processed features

STEP 2: Train ML Models (Supervised & Unsupervised)
  ‚úì Random Forest Classifier
  ‚úì Gradient Boosting Classifier  
  ‚úì Logistic Regression
  ‚úì Support Vector Machine (SVM)
  ‚úì K-Means Clustering (market regimes)
  ‚úì PCA (dimensionality reduction)

STEP 3: Evaluate Models
  ‚úì Calculate metrics (Accuracy, Precision, Recall, F1, ROC-AUC)
  ‚úì Generate confusion matrices
  ‚úì Plot ROC curves
  ‚úì Cross-validation scores
  ‚úì Feature importance analysis

STEP 4: Make Predictions
  ‚úì Load trained models
  ‚úì Predict price direction for all assets
  ‚úì Ensemble voting for robust predictions
  ‚úì Save predictions for dashboard

STEP 5: View Results
  ‚úì Start web dashboard
  ‚úì See real-time predictions
  ‚úì View model performance reports
    """)
    
    print("\n" + "-"*80)
    response = input("\nReady to start? [y/N]: ")
    
    if response.lower() != 'y':
        print("\n‚ùå Cancelled. Run this script again when ready.")
        return
    
    # Step 1: Feature Engineering
    print_header("STEP 1: Feature Engineering with Apache Spark")
    print("Running: spark_streaming_processor.py")
    print("\nThis will:")
    print("  ‚Ä¢ Load raw price data")
    print("  ‚Ä¢ Calculate 15 technical indicators")
    print("  ‚Ä¢ Save to processed_features.csv")
    print("\n‚è≥ This may take 1-2 minutes...")
    
    os.chdir(BASE_DIR)
    os.system(f"{sys.executable} scripts/spark_streaming_processor.py")
    
    input("\n‚úÖ Step 1 complete. Press Enter to continue...")
    
    # Step 2: Train Models
    print_header("STEP 2: Train ML Models (Supervised & Unsupervised)")
    print("Running: ml_trainer.py")
    print("\nThis will train:")
    print("  ‚Ä¢ Random Forest (100 trees)")
    print("  ‚Ä¢ Gradient Boosting (100 estimators)")
    print("  ‚Ä¢ Logistic Regression")
    print("  ‚Ä¢ SVM (RBF kernel)")
    print("  ‚Ä¢ K-Means (4 clusters)")
    print("  ‚Ä¢ PCA (95% variance)")
    print("\n‚è≥ This may take 2-5 minutes...")
    
    os.system(f"{sys.executable} scripts/ml_trainer.py")
    
    input("\n‚úÖ Step 2 complete. Press Enter to continue...")
    
    # Step 3: Evaluate Models
    print_header("STEP 3: Evaluate Model Performance")
    print("Running: ml_evaluator.py")
    print("\nThis will generate:")
    print("  ‚Ä¢ Confusion matrices")
    print("  ‚Ä¢ ROC curves")
    print("  ‚Ä¢ Metrics comparison chart")
    print("  ‚Ä¢ Feature importance plots")
    print("  ‚Ä¢ Cross-validation results")
    print("  ‚Ä¢ HTML evaluation report")
    print("\n‚è≥ This may take 1-2 minutes...")
    
    os.system(f"{sys.executable} scripts/ml_evaluator.py")
    
    input("\n‚úÖ Step 3 complete. Press Enter to continue...")
    
    # Step 4: Make Predictions
    print_header("STEP 4: Generate Predictions")
    print("Running: ml_predictor.py")
    print("\nThis will:")
    print("  ‚Ä¢ Load trained models")
    print("  ‚Ä¢ Make predictions for all 14 assets")
    print("  ‚Ä¢ Use ensemble voting")
    print("  ‚Ä¢ Save to latest_predictions.json")
    
    os.system(f"{sys.executable} scripts/ml_predictor.py")
    
    input("\n‚úÖ Step 4 complete. Press Enter to continue...")
    
    # Step 5: Results
    print_header("STEP 5: View Results")
    
    print("\nüìä Model Evaluation Report:")
    report_path = os.path.join(BASE_DIR, "reports", "evaluation_report.html")
    if os.path.exists(report_path):
        print(f"   ‚úì Open in browser: {report_path}")
    else:
        print("   ‚ö†Ô∏è  Report not found")
    
    print("\nüéØ Predictions:")
    predictions_path = os.path.join(BASE_DIR, "data", "latest_predictions.json")
    if os.path.exists(predictions_path):
        print(f"   ‚úì Saved to: {predictions_path}")
        
        # Show sample prediction
        import json
        with open(predictions_path, 'r') as f:
            predictions = json.load(f)
        
        if predictions:
            print("\n   üìà Sample Prediction:")
            sample = predictions[0]
            print(f"      Asset: {sample['asset']}")
            print(f"      Direction: {sample['direction']}")
            print(f"      Confidence: {sample['confidence']:.1%}")
            print(f"      Market Regime: {sample.get('market_regime', 'Unknown')}")
    else:
        print("   ‚ö†Ô∏è  Predictions not found")
    
    print("\nüåê Web Dashboard:")
    print("   To view predictions in real-time:")
    print(f"   1. Run: {sys.executable} app.py")
    print("   2. Open: http://localhost:5000")
    print("   3. Click: üéØ Predictions tab")
    
    print_header("‚úÖ ML PIPELINE COMPLETE!")
    
    print("""
Summary of what was accomplished:

‚úÖ Feature Engineering: Technical indicators calculated
‚úÖ Model Training: 6 models trained (4 supervised + 2 unsupervised)
‚úÖ Model Evaluation: Comprehensive performance metrics generated
‚úÖ Predictions: Real-time predictions for 14 financial assets
‚úÖ Reports: HTML reports and visualizations created

All algorithms are REAL, STANDARD ML algorithms from scikit-learn:
  ‚Ä¢ Random Forest (Breiman, 2001)
  ‚Ä¢ Gradient Boosting (Friedman, 2001)
  ‚Ä¢ Logistic Regression (Cox, 1958)
  ‚Ä¢ Support Vector Machine (Cortes & Vapnik, 1995)
  ‚Ä¢ K-Means Clustering (Lloyd, 1982)
  ‚Ä¢ PCA (Pearson, 1901)

No custom or "cooked up" algorithms - just proven, industry-standard methods!
    """)
    
    print("\nüìö For more information, see:")
    print("   ‚Ä¢ ML_IMPLEMENTATION.md - Complete documentation")
    print("   ‚Ä¢ reports/evaluation_report.html - Model performance")
    print("\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ùå Interrupted by user.")
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
