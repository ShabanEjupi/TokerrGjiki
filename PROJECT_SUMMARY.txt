================================================================================
PROJEKTI DOKTORATURÃ‹ - ANALIZA E AVANCUAR FINANCIARE ME PYSPARK
================================================================================

NIVELI: DoktoraturÃ« (PhD)
UNIVERSITETI: Universiteti i PrishtinÃ«s, Republika e KosovÃ«s
FUSHÃ‹: Big Data Analytics, Financial Computing, Time Series Analysis

================================================================================
ALGORITMET E IMPLEMENTUARA (SI MÃ‹SOI PROFESORI)
================================================================================

âœ“ 1. NULL COUNTING - Analiza e plotÃ«sisÃ« sÃ« tÃ« dhÃ«nave
âœ“ 2. DATA PROFILING - VlerÃ«simi gjithÃ«pÃ«rfshirÃ«s (mean, stddev, variance, skewness, kurtosis)
âœ“ 3. PERCENTILE_APPROX - Llogaritja e kuantileve (P25, P50, P75, P95, P99)
âœ“ 4. RETURNS CALCULATION - Rendimentet ditore, javore, mujore
âœ“ 5. LAG - Operacione tÃ« serive kohore (1, 5, 10, 20 ditÃ«)
âœ“ 6. MOVING AVERAGE - Mesataret lÃ«vizÃ«se (7-ditore, 30-ditore, 90-ditore)
âœ“ 7. STDDEV_SAMP - Devijimi standard i mostrave
âœ“ 8. VOLATILITY COMPUTATION - Volatiliteti historik dhe rolling
âœ“ 9. GROUPBY AGGREGATION - Agregimet MapReduce (mujore, vjetore)
âœ“ 10. WINDOW FUNCTIONS - Rank, dense_rank, percent_rank, ntile

================================================================================
STRUKTURA E PROJEKTIT
================================================================================

analiza_financiare_advanced.py  â†’ Implementimi kryesor (650+ rreshta)
generate_dataset.py             â†’ Gjenerues i dataset-it financiar
download_financial_data.py      â†’ Shkarkimi nga Yahoo Finance
README.md                       â†’ Dokumentimi nÃ« anglisht
README_SHQIP.md                 â†’ Dokumentimi nÃ« shqip (i detajuar)
UDHEZIME_EKZEKUTIM.md          â†’ UdhÃ«zime hap-pas-hapi nÃ« shqip

data_kaggle/
  â””â”€â”€ financial_data.csv        â†’ Dataset financiar (S&P 500 style)

rezultatet_doktorature/         â†’ Outputet CSV
  â”œâ”€â”€ 01_null_counting.csv
  â”œâ”€â”€ 02_data_profiling.csv
  â”œâ”€â”€ 03_monthly_aggregation.csv
  â”œâ”€â”€ 04_yearly_aggregation.csv
  â””â”€â”€ 05_dataset_final_i_plote.csv

vizualizime_doktorature/        â†’ Figurat profesionale
  â”œâ”€â”€ 01_time_series_analysis.png
  â”œâ”€â”€ 02_volatility_analysis.png
  â”œâ”€â”€ 03_volume_analysis.png
  â””â”€â”€ 04_statistical_distribution.png

================================================================================
SI TÃ‹ EKZEKUTONI PROJEKTIN
================================================================================

HAPI 1: Instalimi i Dependency-ve
----------------------------------
python -m pip install pyspark pandas matplotlib seaborn numpy openpyxl

HAPI 2: Gjenerimi i Dataset-it
-------------------------------
python generate_dataset.py

HAPI 3: Ekzekutimi i AnalizÃ«s
------------------------------
python analiza_financiare_advanced.py

================================================================================
KARAKTERISTIKAT KRYESORE
================================================================================

âœ“ Niveli Doktoral - Algoritme tÃ« sofistikuara dhe analiza e thellÃ«
âœ“ PySpark Big Data - PÃ«rpunim i distribuuar pÃ«r miliona rreshta
âœ“ Time Series Analysis - Lag, moving averages, trend detection
âœ“ Financial Mathematics - Returns, volatility, risk metrics
âœ“ MapReduce Paradigm - GroupBy aggregations dhe window functions
âœ“ Statistical Computing - Descriptive & inferential statistics
âœ“ Professional Visualizations - 4 figura nÃ« cilÃ«si tÃ« lartÃ«
âœ“ Dokumentim i PlotÃ« - NÃ« shqip dhe anglisht
âœ“ Production-Ready Code - Clean, commented, maintainable

================================================================================
DATASET-I FINANCIAR
================================================================================

Format: CSV (Date, Open, High, Low, Close, Volume)
Periudha: 2015-01-01 deri 2024-10-22
Rreshta: ~2,470 ditÃ« tregtare
Modeli: Geometric Brownian Motion (realist)
Karakteristikat:
  - Trend pozitiv (~8% vjetor)
  - Volatilitet realist (~25% vjetor)
  - Market crashes dhe bull runs
  - Volume correlation me volatilitet

================================================================================
REZULTATET (OUTPUTS)
================================================================================

CSV FILES (5 files):
--------------------
1. Null Counting - Analiza e vlerave qÃ« mungojnÃ«
2. Data Profiling - Statistika tÃ« detajuara pÃ«r Ã§do kolonÃ«
3. Monthly Aggregation - Agregime mujore (Ã§mim, volume, volatilitet)
4. Yearly Aggregation - Agregime vjetore
5. Dataset Final - Dataset-i i plotÃ« me tÃ« gjitha feature-et e llogaritura

VISUALIZATION FILES (4 PNG files):
----------------------------------
1. Time Series Analysis - Ã‡mimet + MA (7d, 30d, 90d) + Distribution of Returns
2. Volatility Analysis - Rolling Volatility + Correlation Matrix
3. Volume Analysis - Bar chart i volumit tÃ« tregtimit
4. Statistical Distribution - Box plots pÃ«r Ã§mime dhe rendimente

================================================================================
ALGORITMET NÃ‹ DETAJE
================================================================================

1. NULL COUNTING
   - Filter: col.isNull() | isnan(col)
   - Completeness percentage: 100 - (nulls / total) * 100

2. DATA PROFILING
   - Min, Max, Mean, StdDev, Variance
   - Skewness (asimetria), Kurtosis (kuroziteti)

3. PERCENTILE_APPROX
   - P25 (Quartile 1), P50 (Median), P75 (Quartile 3)
   - P95, P99 pÃ«r vlera ekstreme

4. RETURNS CALCULATION
   - Daily: (Price_t - Price_t-1) / Price_t-1 * 100
   - Weekly: 7-day return using lag(7)
   - Monthly: 30-day return using lag(30)

5. LAG OPERATIONS
   - lag(1): Yesterday's price
   - lag(5): 1-week ago price
   - lag(10): 2-weeks ago
   - lag(20): 1-month ago (trading days)

6. MOVING AVERAGES
   - Window: rowsBetween(-N+1, 0)
   - MA_7d: 7-day simple moving average
   - MA_30d: 30-day SMA
   - MA_90d: 90-day SMA (long-term trend)

7. VOLATILITY COMPUTATION
   - Historical: stddev_samp(Daily_Returns)
   - Annualized: Daily_Vol * sqrt(252)
   - Rolling: 30-day rolling standard deviation

8. GROUPBY AGGREGATION
   - Group by Year, Month
   - Aggregate: avg, min, max, sum, stddev_samp
   - MapReduce pattern pÃ«r distributed computing

9. WINDOW FUNCTIONS
   - rank(): Standard ranking
   - dense_rank(): Ranking pa zbrazÃ«tira
   - percent_rank(): Percentile ranking
   - ntile(4): Split nÃ« quartiles

10. STDDEV_SAMP
    - Sample standard deviation (Bessel's correction)
    - Used in volatility calculations
    - Formula: sqrt(sum((x - mean)^2) / (n-1))

================================================================================
KONTRIBUTI AKADEMIK
================================================================================

TeknologjitÃ«:
  - Apache Spark 3.x (Distributed Computing)
  - PySpark SQL & DataFrame API
  - Python 3.8+ (Scientific Computing)
  - Pandas, NumPy (Data Manipulation)
  - Matplotlib, Seaborn (Visualization)

Konceptet:
  - MapReduce programming model
  - Lazy evaluation dhe query optimization
  - Window functions pÃ«r analytical queries
  - Time series analysis methodology
  - Financial risk management
  - Statistical inference

Aplikimi:
  - Portfolio risk assessment
  - Trading strategy backtesting
  - Market trend analysis
  - Volatility forecasting
  - Performance attribution

================================================================================
REFERENCAT SHKENCORE
================================================================================

[1] Zaharia, M., et al. (2016). "Apache Spark: A Unified Engine for Big Data"
[2] Tsay, R. S. (2010). "Analysis of Financial Time Series" (3rd Edition)
[3] Hull, J. C. (2018). "Options, Futures, and Other Derivatives" (10th Ed.)
[4] Hastie, T., et al. (2009). "The Elements of Statistical Learning"
[5] Dean, J., & Ghemawat, S. (2008). "MapReduce: Simplified Data Processing"

================================================================================
PERFORMANCE METRICS
================================================================================

Spark Configuration:
  - Driver Memory: 4GB
  - Adaptive Query Execution: Enabled
  - Partition Coalescing: Automatic
  - Shuffle Partitions: Auto-tuned

Expected Runtime:
  - Dataset Generation: < 1 minute
  - Analysis Execution: 2-5 minutes (depending on data size)
  - Visualization: < 1 minute
  - Total: ~3-7 minutes

Scalability:
  - Can handle millions of rows
  - Distributed processing ready
  - Memory-efficient operations
  - Optimized query plans

================================================================================
PÃ‹RFUNDIMI
================================================================================

Ky projekt demonstron zotÃ«rimin e:

âœ“ Big Data Technologies (Apache Spark)
âœ“ Financial Analytics (Quantitative Finance)
âœ“ Statistical Computing (Advanced Statistics)
âœ“ Time Series Analysis (Econometrics)
âœ“ Software Engineering (Clean Code, Documentation)

Projekti Ã«shtÃ« i pÃ«rshtatshÃ«m pÃ«r:
  âœ“ Disertacione doktorale
  âœ“ Publikime shkencore
  âœ“ Prezantime akademike
  âœ“ Portfolio profesionale
  âœ“ Aplikime industriale

================================================================================
FAKULTETI I SHKENCAVE KOMPJUTERIKE
UNIVERSITETI I PRISHTINÃ‹S
REPUBLIKA E KOSOVÃ‹S ðŸ‡½ðŸ‡°
================================================================================

TÃ« drejta autoriale Â© 2024
PÃ«rdorimi akademik dhe kÃ«rkimor

âœ“âœ“âœ“ PROJEKTI I NIVELIT DOKTORAL âœ“âœ“âœ“
